{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow Case\n",
    "---\n",
    "一个小例子展示tensorflow工作原理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [[ 0.8833946  -0.06681323]] [ 0.06528893]\n",
      "20 [[ 0.28255695  0.14989944]] [ 0.23387896]\n",
      "40 [[ 0.14345604  0.19283505]] [ 0.28187495]\n",
      "60 [[ 0.11050617  0.19981292]] [ 0.29484379]\n",
      "80 [[ 0.10259257  0.20044759]] [ 0.29848024]\n",
      "100 [[ 0.10065655  0.20026791]] [ 0.29953769]\n",
      "120 [[ 0.10017154  0.20011717]] [ 0.29985559]\n",
      "140 [[ 0.10004642  0.20004565]] [ 0.29995394]\n",
      "160 [[ 0.10001304  0.20001683]] [ 0.29998505]\n",
      "180 [[ 0.10000382  0.20000602]] [ 0.29999509]\n",
      "200 [[ 0.10000114  0.2000021 ]] [ 0.29999837]\n"
     ]
    }
   ],
   "source": [
    "# 使用 NumPy 生成假数据(phony data), 总共 100 个点.\n",
    "x_data = np.float32(np.random.rand(2, 100)) # 随机输入,(2, 100)形状的矩阵\n",
    "y_data = np.dot([0.100, 0.200], x_data) + 0.300 # 结果形状，（1， 100）\n",
    "\n",
    "# 构造一个线性模型\n",
    "b = tf.Variable(tf.zeros([1]))    # shape是一个长度是1的向量\n",
    "W = tf.Variable(tf.random_uniform([1, 2], -1.0, 1.0))    # -1 ～ 1 之间的随机张量，形状是(1, 2)\n",
    "y = tf.matmul(W, x_data) + b    # 矩阵乘法，开始拟合判断\n",
    "\n",
    "# 最小化 **方差**\n",
    "loss = tf.reduce_mean(tf.square(y - y_data))    # 定义方差计算节点\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.5)    # 定义优化器\n",
    "train = optimizer.minimize(loss)    # 定义优化器最小化计算节点\n",
    "\n",
    "# 初始化变量\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# 启动图 (graph)\n",
    "sess = tf.Session()\n",
    "sess.run(init)    # Variable节点初始化\n",
    "\n",
    "# 拟合平面\n",
    "for step in range(0, 201):\n",
    "    sess.run(train)\n",
    "    if step % 20 == 0:\n",
    "        print(step, sess.run(W), sess.run(b))     # 输出会话器Session跟踪的值\n",
    "\n",
    "# 得到最佳拟合结果 W: [[0.100  0.200]], b: [0.300]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow 基本使用说明\n",
    "---\n",
    "\n",
    "1. 工作模式\n",
    "    * 使用计算图表示任务\n",
    "        \n",
    "        1. 图中存在节点，节点表示对张量Tensor的处理，输入多个(or 0)个张量，输出多个(or 0)个张量\n",
    "        \n",
    "    * 使用会话执行图\n",
    "    \n",
    "        1. 会话启动图\n",
    "        2. 会话将图中要计算的节点分发到不同的 CPU / GPU 等计算设备中\n",
    "    \n",
    "    * Tensor传递数据 ： 多维数组的超集\n",
    "        \n",
    "        1. `Python` : `numpy:ndarray`\n",
    "        2. `C++`    : `tensorflow::Tensor`\n",
    "        \n",
    "    * 变量维护状态\n",
    "    * `feed` / `fetch`(`session.run`) 获取数据\n",
    "    \n",
    "2. 基本解释\n",
    "    \n",
    "    1. 计算图\n",
    "    \n",
    "        * 构建图 : \n",
    "        \n",
    "            1. op 的执行步骤被描述成一个图\n",
    "            \n",
    "            2. 一般都是在构建阶段设计构建表示神经网络\n",
    "            \n",
    "            3. 构建方式\n",
    "                \n",
    "                1. 源`Op` : 输入的`Op`节点,一般都是`tf.placeholder`, `tf.constant`等等\n",
    "                2. `Op` : `op` 构造器的返回值代表被构造出的 `op` 的输出, 这些返回值可以传递给其它 `op` 构造器作为输入\n",
    "                \n",
    "            4. 默认图构建，我们一般来说，使用默认图已经足够了\n",
    "            \n",
    "        * 执行图 : \n",
    "            \n",
    "            1. 使用会话执行执行图中的 op.\n",
    "            \n",
    "            2. 执行的过程中，反复计算节点和训练神经网络\n",
    "            \n",
    "            3. 返回`numpy:ndarray`对象\n",
    "            \n",
    "    2. Tensor\n",
    "    \n",
    "    3. Variable : \n",
    "    \n",
    "        1. 变量维护图执行过程中的状态信息\n",
    "        2. 在神经网络中，我们通常可以将网络参数作为权值保存在变量中并在训练过程中不断的更新"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 创建一个常量 op, 产生一个 1x2 矩阵. 这个 op 被作为一个节点\n",
    "# 加到默认图中.\n",
    "\n",
    "# 构造器的返回值代表该常量 op 的返回值.\n",
    "matrix1 = tf.constant([[3., 3.]])\n",
    "\n",
    "# 创建另外一个常量 op, 产生一个 2x1 矩阵.\n",
    "matrix2 = tf.constant([[2.],[2.]])\n",
    "\n",
    "# 创建一个矩阵乘法 matmul op , 把 'matrix1' 和 'matrix2' 作为输入. 结果是 (1, 1)的矩阵\n",
    "# 返回值 'product' 代表矩阵乘法的结果.\n",
    "product = tf.matmul(matrix1, matrix2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 12.]] <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# 启动图\n",
    "with tf.Session() as sess:\n",
    "    result = sess.run(product)\n",
    "    print(result, type(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "# 让变量成为一个计数器\n",
    "# 创建一个变量, 初始化为标量 0.\n",
    "state = tf.Variable(0, name=\"counter\")\n",
    "\n",
    "one = tf.constant(1)\n",
    "new_value = tf.add(state, one)\n",
    "# 更新variable的状态\n",
    "update = tf.assign(state, new_value)\n",
    "\n",
    "# 启动图后, 变量必须先经过`初始化` (init) op 初始化,\n",
    "# 首先必须增加一个`初始化` op 到图中.\n",
    "init_op = tf.global_variables_initializer()\n",
    "\n",
    "# 启动图, 运行 op\n",
    "with tf.Session() as sess:\n",
    "    # 运行 'init' op\n",
    "    sess.run(init_op)\n",
    "    # 打印 'state' 的初始值\n",
    "    print(sess.run(state))\n",
    "    # 运行 op, 更新 'state', 并打印 'state'\n",
    "    for _ in range(3):\n",
    "        sess.run(update)\n",
    "        print(sess.run(state))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 ML",
   "language": "python",
   "name": "pythonml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
